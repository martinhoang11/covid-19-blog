{
  
    
        "post0": {
            "title": "Title",
            "content": "CORONA-VIRUS(COVID-19) . im = PIL.Image.open(&quot;images/corona.jpg&quot;) display(im.resize((600,400), 0)) . In this notebook I will research on the tracks of spread of novel corona-virus, also known as COVID-19 or SARS-CoV-2. It is contagious respiratory virus that first started in Wuhan in December 2019. On 2/11/2020, the pandemic is offically name COVID-19 by the World Health Organization. At first, It is thought like as others normal virus: H5N1, H5N9,... Many countries in the world are not aware of this pandemic which have failed in control the spreading now. So today I want to research and visualize some information about this pandemic and build a model to predict the X-ray chest of COVID-19&#39;s victim. Let&#39;s start ! . You can find the data here: . Data update everyday: https://github.com/CSSEGISandData/COVID-19 | Learn more from WHO | Learn more from CDC | Source code is on my github | . Import libary . import pandas as pd import seaborn as sns import matplotlib.pyplot as plt import matplotlib.colors as mcolors import plotly.express as px import plotly.offline as py import numpy as np import cv2 import os import warnings import datetime import operator import random import PIL from sklearn.linear_model import LinearRegression, BayesianRidge from sklearn.model_selection import RandomizedSearchCV, train_test_split from sklearn.svm import SVR %matplotlib inline warnings.filterwarnings(&#39;ignore&#39;) . Take a look at data . Last update: 3/27/2020 3:30PM | . confirmed_data = pd.read_csv(&#39;COVID-19-master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv&#39;) deaths_data = pd.read_csv(&#39;COVID-19-master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv&#39;) recoverd_data = pd.read_csv(&#39;COVID-19-master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv&#39;) age_data = pd.read_csv(&#39;coronavirusdataset/COVID-19_Age.csv&#39;) . confirmed_data.head() . Province/State Country/Region Lat Long 1/22/20 1/23/20 1/24/20 1/25/20 1/26/20 1/27/20 ... 3/18/20 3/19/20 3/20/20 3/21/20 3/22/20 3/23/20 3/24/20 3/25/20 3/26/20 3/27/20 . 0 NaN | Afghanistan | 33.0000 | 65.0000 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 22 | 22 | 24 | 24 | 40 | 40 | 74 | 84 | 94 | 110 | . 1 NaN | Albania | 41.1533 | 20.1683 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 59 | 64 | 70 | 76 | 89 | 104 | 123 | 146 | 174 | 186 | . 2 NaN | Algeria | 28.0339 | 1.6596 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 74 | 87 | 90 | 139 | 201 | 230 | 264 | 302 | 367 | 409 | . 3 NaN | Andorra | 42.5063 | 1.5218 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 39 | 53 | 75 | 88 | 113 | 133 | 164 | 188 | 224 | 267 | . 4 NaN | Angola | -11.2027 | 17.8739 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 1 | 2 | 2 | 3 | 3 | 3 | 4 | 4 | . 5 rows × 70 columns . cols = confirmed_data.keys() . confirmed = confirmed_data.loc[:, cols[4]:cols[-1]] deaths = deaths_data.loc[:, cols[4]:cols[-1]] recovered = recoverd_data.loc[:, cols[4]:cols[-1]] . dates = confirmed.keys() world_cases = [] total_deaths = [] mortality_rate = [] recovery_rate = [] total_recovered = [] total_active = [] china_cases = [] italy_cases = [] us_cases = [] spain_cases = [] for i in dates: confirmed_sum = confirmed[i].sum() death_sum = deaths[i].sum() recovered_sum = recovered[i].sum() # confirmed, deaths, recovered, and active world_cases.append(confirmed_sum) total_deaths.append(death_sum) total_recovered.append(recovered_sum) total_active.append(confirmed_sum-death_sum-recovered_sum) # calculate rates mortality_rate.append(death_sum/confirmed_sum) recovery_rate.append(recovered_sum/confirmed_sum) # case studies china_cases.append(confirmed_data[confirmed_data[&#39;Country/Region&#39;]==&#39;China&#39;][i].sum()) italy_cases.append(confirmed_data[confirmed_data[&#39;Country/Region&#39;]==&#39;Italy&#39;][i].sum()) us_cases.append(confirmed_data[confirmed_data[&#39;Country/Region&#39;]==&#39;US&#39;][i].sum()) spain_cases.append(confirmed_data[confirmed_data[&#39;Country/Region&#39;]==&#39;Spain&#39;][i].sum()) . def daily_increase(data): d = [] for i in range(len(data)): if i == 0: d.append(data[0]) else: d.append(data[i]-data[i-1]) return d world_daily_increase = daily_increase(world_cases) china_daily_increase = daily_increase(china_cases) italy_daily_increase = daily_increase(italy_cases) us_daily_increase = daily_increase(us_cases) spain_daily_increase = daily_increase(spain_cases) . days_since_1_22 = np.array([i for i in range(len(dates))]).reshape(-1, 1) world_cases = np.array(world_cases).reshape(-1, 1) total_deaths = np.array(total_deaths).reshape(-1, 1) total_recovered = np.array(total_recovered).reshape(-1, 1) . days_in_future = 10 future_forcast = np.array([i for i in range(len(dates)+days_in_future)]).reshape(-1, 1) adjusted_dates = future_forcast[:-10] . adjusted_dates = adjusted_dates.reshape(1, -1)[0] plt.figure(figsize=(12, 9)) plt.plot(adjusted_dates, world_cases) plt.title(&#39;# of Coronavirus Cases Over Time&#39;, size=22) plt.xlabel(&#39;Days Since 1/22/2020&#39;, size=22) plt.ylabel(&#39;# of Cases&#39;, size=22) plt.xticks(size=20) plt.yticks(size=20) plt.show() . plt.figure(figsize=(12, 9)) plt.plot(adjusted_dates, np.log10(world_cases)) plt.title(&#39;Log of # of Coronavirus Cases Over Time&#39;, size=22) plt.xlabel(&#39;Days Since 1/22/2020&#39;, size=22) plt.ylabel(&#39;# of Cases&#39;, size=22) plt.xticks(size=20) plt.yticks(size=20) plt.show() . plt.figure(figsize=(12, 9)) plt.bar(adjusted_dates, world_daily_increase) plt.title(&#39;World Daily Increases in Confirmed Cases&#39;, size=22) plt.xlabel(&#39;Days Since 1/22/2020&#39;, size=22) plt.ylabel(&#39;# of Cases&#39;, size=22) plt.xticks(size=20) plt.yticks(size=20) plt.show() . plt.figure(figsize=(12, 9)) plt.bar(adjusted_dates, china_daily_increase) plt.title(&#39;China Daily Increases in Confirmed Cases&#39;, size=22) plt.xlabel(&#39;Days Since 1/22/2020&#39;, size=22) plt.ylabel(&#39;# of Cases&#39;, size=22) plt.xticks(size=20) plt.yticks(size=20) plt.show() . plt.figure(figsize=(12, 9)) plt.bar(adjusted_dates, italy_daily_increase) plt.title(&#39;Italy Daily Increases in Confirmed Cases&#39;, size=22) plt.xlabel(&#39;Days Since 1/22/2020&#39;, size=22) plt.ylabel(&#39;# of Cases&#39;, size=22) plt.xticks(size=20) plt.yticks(size=20) plt.show() . plt.figure(figsize=(12, 9)) plt.bar(adjusted_dates, us_daily_increase) plt.title(&#39;USA Daily Increases in Confirmed Cases&#39;, size=22) plt.xlabel(&#39;Days Since 1/22/2020&#39;, size=22) plt.ylabel(&#39;# of Cases&#39;, size=22) plt.xticks(size=20) plt.yticks(size=20) plt.show() . plt.figure(figsize=(12, 9)) plt.bar(adjusted_dates, spain_daily_increase) plt.title(&#39;Spain Daily Increases in Confirmed Cases&#39;, size=22) plt.xlabel(&#39;Days Since 1/22/2020&#39;, size=22) plt.ylabel(&#39;# of Cases&#39;, size=22) plt.xticks(size=20) plt.yticks(size=20) plt.show() . plt.figure(figsize=(12, 9)) plt.plot(adjusted_dates, china_cases) plt.plot(adjusted_dates, italy_cases) plt.plot(adjusted_dates, us_cases) plt.plot(adjusted_dates, spain_cases) plt.title(&#39;# of Coronavirus Cases&#39;, size=22) plt.xlabel(&#39;Days Since 1/22/2020&#39;, size=22) plt.ylabel(&#39;# of Cases&#39;, size=22) plt.legend([&#39;China&#39;, &#39;Italy&#39;, &#39;US&#39;, &#39;Spain&#39;], prop={&#39;size&#39;: 20}) plt.xticks(size=20) plt.yticks(size=20) plt.show() . start = &#39;1/22/2020&#39; start_date = datetime.datetime.strptime(start, &#39;%m/%d/%Y&#39;) future_forcast_dates = [] for i in range(len(future_forcast)): future_forcast_dates.append((start_date + datetime.timedelta(days=i)).strftime(&#39;%m/%d/%Y&#39;)) . X_train_confirmed, X_test_confirmed, y_train_confirmed, y_test_confirmed = train_test_split(days_since_1_22, world_cases, test_size=0.05, shuffle=False) . svm_confirmed = SVR(shrinking=True, kernel=&#39;poly&#39;,gamma=0.01, epsilon=1,degree=8, C=0.1) svm_confirmed.fit(X_train_confirmed, y_train_confirmed) svm_pred = svm_confirmed.predict(future_forcast) . print(&#39;SVM future predictions:&#39;) set(zip(future_forcast_dates[-10:], np.round(svm_pred[-10:]))) . SVM future predictions: . {(&#39;03/28/2020&#39;, 647952.0), (&#39;03/29/2020&#39;, 722249.0), (&#39;03/30/2020&#39;, 804728.0), (&#39;03/31/2020&#39;, 896149.0), (&#39;04/01/2020&#39;, 997331.0), (&#39;04/02/2020&#39;, 1109152.0), (&#39;04/03/2020&#39;, 1232560.0), (&#39;04/04/2020&#39;, 1368567.0), (&#39;04/05/2020&#39;, 1518260.0), (&#39;04/06/2020&#39;, 1682804.0)} . plt.figure(figsize=(12, 9)) plt.plot(adjusted_dates, total_active, color=&#39;purple&#39;) plt.title(&#39;# of Coronavirus Active Cases Over Time&#39;, size=22) plt.xlabel(&#39;Days Since 1/22/2020&#39;, size=22) plt.ylabel(&#39;# of Active Cases&#39;, size=22) plt.xticks(size=20) plt.yticks(size=20) plt.show() . plt.figure(figsize=(12, 9)) plt.plot(adjusted_dates, total_deaths, color=&#39;red&#39;) plt.title(&#39;# of Coronavirus Deaths Over Time&#39;, size=22) plt.xlabel(&#39;Days Since 1/22/2020&#39;, size=22) plt.ylabel(&#39;# of Deaths&#39;, size=22) plt.xticks(size=20) plt.yticks(size=20) plt.show() . plt.figure(figsize=(12,9)) plt.plot(adjusted_dates, total_recovered, color=&#39;green&#39;) plt.title(&#39;# of Coronavirus Cases Recovered Over Time&#39;, size=22) plt.xlabel(&#39;Days Since 1/22/2020&#39;, size=22) plt.ylabel(&#39;# of Cases&#39;, size=22) plt.xticks(size=20) plt.yticks(size=20) plt.show() . plt.figure(figsize=(12, 9)) plt.plot(adjusted_dates, total_deaths, color=&#39;r&#39;) plt.plot(adjusted_dates, total_recovered, color=&#39;green&#39;) plt.legend([&#39;death&#39;, &#39;recoveries&#39;], loc=&#39;best&#39;, fontsize=20) plt.title(&#39;# of Coronavirus Cases&#39;, size=22) plt.xlabel(&#39;Days Since 1/22/2020&#39;, size=22) plt.ylabel(&#39;# of Cases&#39;, size=22) plt.xticks(size=20) plt.yticks(size=20) plt.show() . latest_confirmed = confirmed_data[dates[-1]] latest_deaths = deaths_data[dates[-1]] latest_recoveries = recoverd_data[dates[-1]] unique_countries = list(confirmed_data[&#39;Country/Region&#39;].unique()) no_cases = [] country_confirmed_cases = [] for i in unique_countries: cases = latest_confirmed[confirmed_data[&#39;Country/Region&#39;]==i].sum() if cases &gt; 0: country_confirmed_cases.append(cases) else: no_cases.append(i) for i in no_cases: unique_countries.remove(i) # sort countries by the number of confirmed cases unique_countries = [k for k, v in sorted(zip(unique_countries, country_confirmed_cases), key=operator.itemgetter(1), reverse=True)] for i in range(len(unique_countries)): country_confirmed_cases[i] = latest_confirmed[confirmed_data[&#39;Country/Region&#39;]==unique_countries[i]].sum() . # Only show 10 countries with the most confirmed cases, the rest are grouped into the other category visual_unique_countries = [] visual_confirmed_cases = [] others = np.sum(country_confirmed_cases[10:]) for i in range(len(country_confirmed_cases[:10])): visual_unique_countries.append(unique_countries[i]) visual_confirmed_cases.append(country_confirmed_cases[i]) visual_unique_countries.append(&#39;Others&#39;) visual_confirmed_cases.append(others) . plt.figure(figsize=(12, 9)) plt.barh(visual_unique_countries, visual_confirmed_cases) plt.title(&#39;# of Covid-19 Confirmed Cases in Countries/Regions&#39;, size=20) plt.xticks(size=20) plt.yticks(size=20) plt.show() . c = random.choices(list(mcolors.CSS4_COLORS.values()),k = len(unique_countries)) plt.figure(figsize=(20,15)) plt.title(&#39;Covid-19 Confirmed Cases per Country&#39;, size=20) plt.pie(visual_confirmed_cases, colors=c) plt.legend(visual_unique_countries, loc=&#39;best&#39;, fontsize=15) plt.show() . c = random.choices(list(mcolors.CSS4_COLORS.values()),k = len(unique_countries)) plt.figure(figsize=(20,15)) plt.title(&#39;Covid-19 Confirmed Cases in Countries Outside of Mainland China&#39;, size=20) plt.pie(visual_confirmed_cases[1:], colors=c) plt.legend(visual_unique_countries[1:], loc=&#39;best&#39;, fontsize=15) plt.show() . Another dataset . case_data = pd.read_csv(&#39;coronavirusdataset/Case.csv&#39;) patient_info_data = pd.read_csv(&#39;coronavirusdataset/PatientInfo.csv&#39;) route_data = pd.read_csv(&#39;coronavirusdataset/TimeGender.csv&#39;) gender = pd.read_csv(&#39;coronavirusdataset/TimeGender.csv&#39;) . bins = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99, 109, 119, 129] labels=[&#39;0-9&#39;,&#39;10-19&#39;, &#39;20-29&#39;, &#39;30-39&#39;, &#39;40-49&#39;, &#39;50-59&#39;, &#39;60-69&#39;, &#39;70-79&#39;, &#39;80-89&#39;, &#39;90-99&#39;, &#39;100-109&#39;, &#39;110-119&#39;, &#39;120-129&#39;] age_data[&#39;range_age&#39;] = pd.cut(age_data[&#39;Age_end&#39;], bins=bins, labels=labels, include_lowest=True) . #italy_data = age_data[age_data[&#39;Country&#39;] == &#39;Italy&#39;][[&#39;Positive&#39;, &#39;range_age&#39;, &#39;Country&#39;]] . About Age . # fig = px.pie( values=age_data.groupby([&#39;range_age&#39;]).size().values,names=age_data.groupby([&#39;range_age&#39;]).size().index) # fig.update_layout( # font=dict( # size=20, # color=&quot;#242323&quot; # ) # ) #py.iplot(fig) im = PIL.Image.open(&quot;images/age_pie.png&quot;) display(im.resize((800,500), 0)) . About gender . sns.barplot(x=&quot;sex&quot;, y=&quot;confirmed&quot;, hue=&quot;sex&quot;, data=gender).set_title(&#39;Confirmed cases from 02/03 -&gt; 22/03&#39;) . Text(0.5, 1.0, &#39;Confirmed cases from 02/03 -&gt; 22/03&#39;) . Chest X-Ray COVID-19 Classification . Before get to work into this field, I want to talk about some problem. Firstly, this is my research on X-Ray chest, and I just use my own available knowledge to apply. So if you have any confuses or complains please give a feedback to me at my facebook ^^. Thank you and have fun ! . You can find the dataset in this link, this dataset is already use augmentation techniques ! | The organization of folder as below: . Dataset_COVID-19_Augmented (root) . ~ Images with COVID-19: COVID-19 (child folder) . ~ Images with NON-COVID-19: Non-COVID-19 (child folder) . | . | . Take a look at some differences between COVID-19&#39;s chest x-ray and NON-COVID-19&#39;s chest x-ray . #path images_path = &#39;/Users/huynh/OCR/covid-19/Dataset_COVID-19_Augmented&#39; covid19_path = os.path.join(images_path, &#39;COVID-19&#39;) non_covid19_path = os.path.join(images_path, &#39;Non-COVID-19&#39;) covid19 = [] non_covid19 = [] #load data for i in os.listdir(os.path.join(images_path, &#39;COVID-19&#39;)): covid19.append(i) for i in os.listdir(os.path.join(images_path, &#39;Non-COVID-19&#39;)): non_covid19.append(i) print(f&#39;Total images: {len(covid19) + len(non_covid19)}&#39;) . Total images: 1806 . COVID-19 images . fig=plt.figure(figsize=(20, 20)) columns = 3 rows = 5 for i, j in enumerate(covid19[:15]): img = cv2.imread(os.path.join(covid19_path, j)) fig.add_subplot(rows, columns, i+1) plt.title(j) plt.axis(&#39;off&#39;) plt.imshow(img) plt.show() . fig=plt.figure(figsize=(20, 20)) columns = 3 rows = 5 for i, j in enumerate(non_covid19[:15]): img = cv2.imread(os.path.join(non_covid19_path, j)) fig.add_subplot(rows, columns, i+1) plt.title(j) plt.axis(&#39;off&#39;) plt.imshow(img) plt.show() . More images about the differences . im = PIL.Image.open(&quot;images/img_01.jpg&quot;) display(im.resize((600,400), 0)) . im = PIL.Image.open(&quot;images/0_Coronavirus-Chest-Xray.jpg&quot;) display(im.resize((600,700), 0)) . im = PIL.Image.open(&quot;images/Fig 2.tif&quot;) display(im.resize((600,1000), 0)) . im = PIL.Image.open(&quot;images/covid-19-radiologist-perspective-chest-x-ray-fb23.png&quot;) display(im.resize((800,600), 0)) . About some images shown above, we can see that the lungs have COV-19 are quite more blur than the normal lung X-ray. According to this article, with the purpose of diagnose cancer chest X-ray still have a series of several questions. &quot;The quick answer is that more than 20% of lung cancers may be missed on a chest X-ray&quot; but with the system of AI tools nowadays, the computer can diagnose are gradually more accuarate than people. So I decided to try to build a model classify COV-19 images. . #import libary import tensorflow as tf from tensorflow.keras.models import load_model from tensorflow.keras.preprocessing.image import ImageDataGenerator from tensorflow.keras.applications import VGG16 from tensorflow.keras.layers import AveragePooling2D from tensorflow.keras.layers import Dropout from tensorflow.keras.layers import Flatten from tensorflow.keras.layers import Dense from tensorflow.keras.layers import Input from tensorflow.keras.models import Model from tensorflow.keras.optimizers import Adam from tensorflow.keras.utils import to_categorical from sklearn.preprocessing import LabelBinarizer from sklearn.model_selection import train_test_split from sklearn.metrics import classification_report from sklearn.metrics import confusion_matrix from imutils import paths np.random.seed(38) . #initialize some variables lr = 1e-3 epochs = 5 batch_size = 8 . img_data = list(paths.list_images(images_path)) data = [] labels = [] . for img in img_data: label = img.split(os.path.sep)[-2] image = cv2.imread(img) image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) image = cv2.resize(image, (224, 224)) data.append(image) labels.append(label) #scale image data = np.array(data) / 255.0 labels = np.array(labels) #create one-hot encoding lb = LabelBinarizer() labels = lb.fit_transform(labels) labels = to_categorical(labels) . (x_train, x_test, y_train, y_test) = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42) . data_generator = ImageDataGenerator( horizontal_flip=True, fill_mode=&#39;neareast&#39;) . #load VGG16 pretrain model vgg16_model = VGG16(weights=&#39;imagenet&#39;, include_top=False, input_tensor=Input(shape=(224,224,3))) #build output model model = vgg16_model.output model = AveragePooling2D(pool_size=(2,2))(model) model = Flatten()(model) model = Dense(128, activation=&#39;relu&#39;)(model) model = Dropout(0.2)(model) model = Dense(256, activation=&#39;relu&#39;)(model) model = Dropout(0.2)(model) model = Dense(512, activation=&#39;relu&#39;)(model) model = Dropout(0.2)(model) model = Dense(2, activation=&#39;softmax&#39;)(model) model = Model(inputs=vgg16_model.input, outputs=model) #freeze top layers VGG16 layers for layer in vgg16_model.layers: layer.trainable = False optimize = Adam(lr=lr, decay=lr/epochs) model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=optimize, metrics=[&#39;accuracy&#39;]) history = model.fit_generator( data_generator.flow(x_train, y_train, batch_size=batch_size), steps_per_epoch=len(x_train) // batch_size, validation_data=(x_test, y_test), validation_steps=len(x_test) // batch_size, epochs=epochs) . Epoch 1/5 180/180 [==============================] - 291s 2s/step - loss: 0.1261 - acc: 0.9498 - val_loss: 0.0196 - val_acc: 0.9945 Epoch 2/5 180/180 [==============================] - 298s 2s/step - loss: 0.0551 - acc: 0.9784 - val_loss: 0.0154 - val_acc: 0.9945 Epoch 3/5 180/180 [==============================] - 299s 2s/step - loss: 0.0453 - acc: 0.9861 - val_loss: 0.0113 - val_acc: 0.9945 Epoch 4/5 180/180 [==============================] - 300s 2s/step - loss: 0.0145 - acc: 0.9951 - val_loss: 0.0210 - val_acc: 0.9945 Epoch 5/5 180/180 [==============================] - 302s 2s/step - loss: 0.0162 - acc: 0.9951 - val_loss: 0.0032 - val_acc: 1.0000 . #predict the x_test and make a classification report pred = model.predict(x_test, batch_size=batch_size) pred = np.argmax(pred, axis=1) print(classification_report(y_test.argmax(axis=1), pred, target_names=lb.classes_)) . precision recall f1-score support COVID-19 1.00 1.00 1.00 180 Non-COVID-19 1.00 1.00 1.00 181 accuracy 1.00 361 macro avg 1.00 1.00 1.00 361 weighted avg 1.00 1.00 1.00 361 . #create confusion matrix and compute the accuracy oof the model confusion_matrix = confusion_matrix(y_test.argmax(axis=1), pred) total = sum(sum(confusion_matrix)) acc = (confusion_matrix[0, 0] + confusion_matrix[1, 1]) / total print(confusion_matrix) print(&#39;Accuracy: {:.4f}&#39;.format(acc)) . [[180 0] [ 0 181]] Accuracy: 1.0000 . sns.heatmap(confusion_matrix, annot=True) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x177afa7b8&gt; . N = epochs plt.style.use(&quot;ggplot&quot;) plt.figure(figsize=(8,8)) plt.plot(np.arange(0, N), history.history[&quot;loss&quot;], label=&quot;train_loss&quot;) plt.plot(np.arange(0, N), history.history[&quot;val_loss&quot;], label=&quot;val_loss&quot;) plt.plot(np.arange(0, N), history.history[&quot;acc&quot;], label=&quot;train_acc&quot;) plt.plot(np.arange(0, N), history.history[&quot;val_acc&quot;], label=&quot;val_acc&quot;) plt.title(&quot;Training Loss and Accuracy on COVID-19 Dataset&quot;) plt.xlabel(&quot;Epoch #&quot;) plt.ylabel(&quot;Loss/Accuracy&quot;) plt.legend(loc=&quot;lower left&quot;) # plt.savefig(&#39;.&#39;) . &lt;matplotlib.legend.Legend at 0x1ef99ff60&gt; . With the weights of VGG16 model we can see that the model converge really fast and get the high accuracy about 98.6% | . model.save(&#39;./model/covid19.h5&#39;, model) . Let&#39;s predict some test images . #load model covid_model = load_model(&#39;./model/covid19.h5&#39;) test_path = list(paths.list_images(&#39;test/&#39;)) . WARNING:tensorflow:From /Users/huynh/opt/anaconda3/envs/ocr/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version. Instructions for updating: Call initializer instance with the dtype argument instead of passing it to the constructor WARNING:tensorflow:From /Users/huynh/opt/anaconda3/envs/ocr/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version. Instructions for updating: Call initializer instance with the dtype argument instead of passing it to the constructor WARNING:tensorflow:From /Users/huynh/opt/anaconda3/envs/ocr/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version. Instructions for updating: Call initializer instance with the dtype argument instead of passing it to the constructor WARNING:tensorflow:From /Users/huynh/opt/anaconda3/envs/ocr/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.&lt;locals&gt;.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version. Instructions for updating: Use tf.where in 2.0, which has the same broadcast rule as np.where . test_data = [] test_labelss = [] for img in test_path: label = img.split(os.path.sep)[-1].split(&#39;_&#39;)[0] image = cv2.imread(img) image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) image = cv2.resize(image, (224, 224)) test_data.append(image) test_labelss.append(label) test_labels = lb.fit_transform(test_labelss) test_labels = to_categorical(test_labels) test_labels = np.argmax(test_labels, axis=1) . pred_labels = covid_model.predict(np.array(test_data), batch_size=batch_size) pred_labels = np.argmax(pred_labels, axis=1) . print(f&#39;Labels: {test_labels}&#39;) print(f&#39;Predict labels: {pred_labels}&#39;) . Labels: [1 1 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0] Predict labels: [1 1 1 1 1 1 0 1 1 1 0 1 0 0 0 0 1 1 1 1] . import sklearn acc = sklearn.metrics.accuracy_score(test_labels, pred_labels) print(f&#39;Accuracy: {round(acc, 2) * 100}%&#39;) . Accuracy: 80.0% . path = &#39;/Users/huynh/OCR/covid-19/&#39; plt.figure(figsize=(15,15)) for n in range(20): plt.subplot(4,5,n+1) plt.subplots_adjust(hspace = 0.3, wspace=0.2) plt.imshow(test_data[n]) color = &quot;blue&quot; if pred_labels[n] == test_labels[n] else &quot;red&quot; plt.title(test_labelss[n], color=color) plt.axis(&#39;off&#39;) _ = plt.suptitle(&quot;Model predictions (blue: correct, red: incorrect)&quot;, fontsize=24) . Hope you enjoy it, Thank you ! . Author: HuyNg. .",
            "url": "https://martinhoang11.github.io/covid-19-blog/2020/02/04/COVID19-Research.html",
            "relUrl": "/2020/02/04/COVID19-Research.html",
            "date": " • Feb 4, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://martinhoang11.github.io/covid-19-blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://martinhoang11.github.io/covid-19-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}